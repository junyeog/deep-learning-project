## 딥러닝 프로젝트 최종 보고서: 다양한 데이터 기반 성별 분류 모델 개발 및 성능 분석

* 20242403 오준역 발표 :X

### 1. 프로젝트 소개

다양한 형태의 데이터를 활용하여 개인의 성별을 효과적으로 예측하는 머신러닝 및 딥러닝 모델을 구축하고 그 성능을 비교 분석하는 것을 목표로 합니다. 얼굴의 수치형 데이터, 트위터 사용자의 텍스트 및 정보, 음성 특징, 그리고 얼굴 이미지 등 네 가지 독립적인 데이터셋을 통해 데이터 유형별 모델 구축 전략 및 성능을 분석합니다.

### 2. 주제 관련 배경

인간의 다양한 특징들은 성별 구분에 있어 중요한 지표가 될 수 있습니다. 얼굴의 형태나 비율, 코의 형태, 입술의 두께와 같은 신체적 특징, 음성의 주파수나 스펙트럼과 같은 청각적 특징, 그리고 소셜 미디어에서의 언어 사용 패턴이나 활동 지표 같은 행동적 특징까지, 이 모든 정보는 성별에 따른 미묘한 차이를 포함합니다.

이 프로젝트는 이러한 다채로운 데이터 유형을 정량화하고 다양한 모델 방식을 적용하여 각 모델의 강점과 약점을 파악합니다. 이를 통해 각 데이터 유형에 가장 적합한 성별 예측 모델을 도출하고자 합니다. 또한, 각 데이터셋의 특성에 따른 데이터 전처리, 모델 하이퍼파라미터 튜닝의 중요성을 강조하고, 모델의 일반화 성능과 신뢰성을 높이는 방안을 모색합니다.

### 3. 데이터셋 개요

본 프로젝트에서는 다음과 같이 네 가지 데이터셋을 활용하여 성별 분류 모델을 구축하고 분석했습니다. 각 데이터셋은 서로 다른 유형의 특징을 포함하며, 이에 따라 다른른 전처리 및 모델링 접근 방식이 적용되었습니다.

* **첫 번째 데이터셋**: `gender_classification_v7.csv` - 얼굴의 특정 수치형 특징(이마 너비/높이, 코 너비/길이, 입술 얇기, 코-입술 거리, 장발 여부) 
* https://www.kaggle.com/datasets/elakiricoder/gender-classification-dataset/data
* **두 번째 데이터셋**: `gender-classifier-DFE-791531.csv` - 소셜 미디어 트윗 텍스트 및 사용자 프로필 관련 수치형 정보 
* *https://www.kaggle.com/datasets/crowdflower/twitter-user-gender-classification?utm_source=chatgpt.com
* **세 번째 데이터셋**: `voice.csv` - 음성 특징(주파수, 스펙트럼 엔트로피 등)
 https://www.kaggle.com/datasets/primaryobjects/voicegender?utm_source=chatgpt.com
* **네 번째 데이터셋**: UTKFace 데이터셋 - 다양한 연령, 성별, 인종의 얼굴 이미지
* https://www.kaggle.com/datasets/jangedoo/utkface-new


---

### 4. 프로젝트 결과: 데이터셋별 모델 분석

### 4.1. 첫 번째 데이터셋: 수치형 얼굴 특징 기반 성별 분류




#### 4.1.1. 데이터셋 소개
사용된 데이터셋은 `gender_classification_v7.csv` 파일로, 총 **5,001개의 샘플(행)**과 8개의 컬럼으로 구성되어 있습니다.

* **컬럼**: `long_hair`, `forehead_width_cm`, `forehead_height_cm`, `nose_wide`, `nose_long`, `lips_thin`, `distance_nose_to_lip_long`, `gender` (타겟)
* **데이터 타입**: `float64`(2), `int64`(5), `object`(1). 모든 컬럼에 결측치(Non-Null Count: 5001)는 존재하지 않습니다.
* **타겟 변수 (`gender`) 분포**: 'Female': 2501 (50.01%), 'Male': 2500 (49.99%)로, 클래스 불균형 없이 균등하게 분포되어 있습니다.

#### 4.1.3. 전처리 과정
1.  **타겟 변수 인코딩**: `gender` 컬럼('Male', 'Female')을 `sklearn.preprocessing.LabelEncoder`를 사용하여 'Female'은 0, 'Male'은 1로 인코딩했습니다.
2.  **피처 스케일링**: `forehead_width_cm` 및 `forehead_height_cm`와 같은 연속형 수치 특성들은 `sklearn.preprocessing.StandardScaler`를 사용하여 평균 0, 표준편차 1인 표준 정규 분포 형태로 스케일링했습니다. 이진 특성(0 또는 1)은 스케일링이 필요하지 않았습니다.
3.  **데이터 분할**: 스케일링이 완료된 데이터를 `train_test_split`을 사용하여 훈련 세트(80%)와 테스트 세트(20%)로 분할했습니다 (`test_size=0.2`, `stratify=y` 적용).

#### 4.1.4. 모델 구조 (머신러닝 및 딥러닝)
**머신러닝 모델**: `sklearn` 라이브러리를 사용하여 Logistic Regression, Decision Tree Classifier, Random Forest Classifier, Support Vector Machine (SVM) with RBF Kernel, K-Nearest Neighbors (KNN) Classifier를 구축했습니다.
**딥러닝 모델 (MLP)**: `tensorflow.keras.models.Sequential` API를 사용한 다층 퍼셉트론 모델입니다.
    * **구조**: 입력층(7개 뉴런) → 은닉층 1 (20개 뉴런, ReLU) → 은닉층 2 (15개 뉴런, ReLU) → 은닉층 3 (10개 뉴런, ReLU) → 출력층 (1개 뉴런, Sigmoid).
    * **컴파일**: `loss='binary_crossentropy'`, `optimizer='adam'`, `metrics=['accuracy']`.
    * **학습**: 50 epoch, batch_size 32. `EarlyStopping` (val_loss 5 epoch), `ModelCheckpoint` (val_accuracy) 콜백 적용.


#### 4.1.5. 프로젝트 결과
**머신러닝 모델 성능 비교**:

| Model               | Accuracy | Precision | Recall | F1-Score | ROC-AUC |
| :------------------ | :------- | :-------- | :----- | :------- | :------ |
| Random Forest       | 0.9850   | 0.9823    | 0.9879 | 0.9851   | 0.9995  |
| SVM (RBF Kernel)    | 0.9840   | 0.9813    | 0.9869 | 0.9841   | 0.9994  |
| Logistic Regression | 0.9810   | 0.9749    | 0.9879 | 0.9814   | 0.9994  |
| Decision Tree       | 0.9700   | 0.9734    | 0.9650 | 0.9692   | 0.9700  |
| K-Nearest Neighbors | 0.9570   | 0.9507    | 0.9640 | 0.9573   | 0.9877  |

* **Random Forest** 모델이 **98.50%**의 가장 높은 정확도와 F1-Score를 달성했습니다.
* **SVM (RBF Kernel)**과 **Logistic Regression**도 각각 98.40%, 98.10%의 높은 정확도를 기록했으며, ROC-AUC는 모두 0.999 이상이었습니다.
* ROC 곡선 및 혼동 행렬 시각화를 통해 Random Forest가 뛰어난 분류 성능을 보였음을 확인했습니다.

**딥러닝 모델 성능**:
* 학습 과정에서 손실(loss)은 감소하고 정확도(accuracy)는 증가하며 안정적으로 수렴하는 양상을 보였습니다.
* **최종 테스트 정확도: 0.981**, **테스트 손실: 0.0632**.
* 이 결과는 딥러닝 모델이 새로운 데이터에 대해서도 약 98.1%의 매우 높은 정확도로 성별을 성공적으로 예측할 수 있음을 보여줍니다.
* ![image](https://github.com/user-attachments/assets/fde856e3-1f00-4f94-bc86-ba993c9d9567)


**모델 종합 비교 및 결론**: Random Forest (98.50% F1-Score)가 가장 높은 성능을 보였고, 딥러닝 MLP 모델 (98.1% 정확도) 또한 매우 뛰어난 성능을 입증했습니다.

---

### 4.2. 두 번째 데이터셋: 소셜 미디어 트윗 및 사용자 특징 기반 성별 분류

#### 4.2.1. 데이터셋 소개
사용된 데이터셋은 `gender-classifier-DFE-791531.csv` 파일로, 총 **20,050개의 샘플(행)**과 26개의 컬럼으로 구성된 트윗 데이터입니다.
* **주요 컬럼**: `gender`(타겟), `text`(트윗 본문), `description`(프로필 설명), `fav_number`, `retweet_count`, `tweet_count`, `created`, `tweet_created` 등.
* **결측치**: `gender`, `description`, `tweet_coord` 등 다양한 컬럼에 결측치가 존재합니다.
* **`gender` 컬럼 분포**: 초기에는 'male', 'female', 'brand', 'unknown', `nan`이 혼재되어 있었으며, 'female' 33.58%, 'male' 31.04%를 차지했습니다.

#### 8.2.3. 전처리 과정
1.  **타겟 변수 필터링 및 인코딩**: 'male'과 'female' 클래스만 남기고, 'brand', 'unknown', `nan`은 제거하여 데이터 수를 12,894개로 줄였습니다. `gender` 분포는 필터링 후 거의 균등해졌으며, `LabelEncoder`를 통해 'female'은 0, 'male'은 1로 인코딩했습니다.
2.  **결측치 처리**: 텍스트 컬럼(`text`, `description`)의 결측치는 빈 문자열로 대체하고, 수치형 컬럼(`fav_number`, `retweet_count`, `tweet_count`)의 결측치는 중앙값으로 대체했습니다.
3.  **텍스트 데이터 정제**: `text`와 `description` 컬럼에 대해 소문자 변환, URL/멘션/해시태그/특수문자/숫자 제거, 토큰화, 불용어 제거, 표제어 추출을 수행했습니다. 정제된 텍스트는 `combined_text` 컬럼으로 결합했습니다.
4.  **수치형 특징 공학**: `created` 및 `tweet_created` 컬럼으로부터 `account_age_days`와 `tweet_age_days`를 계산하여 새로운 수치형 특징으로 추가했습니다.
5.  **텍스트 특징 벡터화**: `combined_text` 컬럼을 `TfidfVectorizer` (max_features=10000, ngram_range=(1,2))를 사용하여 수치형 벡터(`X_tfidf`)로 변환했습니다.
6.  **수치형 특징 스케일링**: 선택된 수치형 특징(`fav_number`, `retweet_count`, `tweet_count`, `account_age_days`, `tweet_age_days`)을 `MinMaxScaler`를 사용하여 [0, 1] 범위로 정규화했습니다.
7.  **특징 결합**: `X_tfidf` (스파스 행렬)와 스케일링된 수치형 특징(Dense 행렬)을 `scipy.sparse.hstack`을 사용하여 `X_combined` (형태: 12894, 10005)로 결합했습니다.
8.  **데이터 분할**: `X_combined`와 `y`를 `train_test_split`을 사용하여 훈련(80%), 테스트(20%) 세트로 분할했습니다 (`test_size=0.2, random_state=42, stratify=y`). 딥러닝 모델 학습을 위해 훈련 세트를 다시 훈련(60%)과 검증(20%) 세트로 분할했습니다.

#### 8.2.4. 모델 구조 (머신러닝 및 딥러닝)
**머신러닝 모델**: Logistic Regression, Decision Tree Classifier, Random Forest Classifier, Support Vector Machine (SVM) with Linear Kernel, K-Nearest Neighbors (KNN) Classifier, Multinomial Naive Bayes (MNB), LightGBM을 구축했습니다.
**딥러닝 모델 (MLP)**: `tensorflow.keras.models.Sequential` API를 사용한 다층 퍼셉트론 모델입니다.
    * **구조**: 입력층(10005개 뉴런) → 은닉층 1 (256개 뉴런, ReLU, Dropout 0.5) → 은닉층 2 (128개 뉴런, ReLU, Dropout 0.3) → 출력층 (1개 뉴런, Sigmoid).
    * **컴파일**: `loss='binary_crossentropy'`, `optimizer='adam'`, `metrics=['accuracy']`.
    * **학습**: 20 epoch, batch size 크기 32, 검증 데이터 (`X_val_dl`, `y_val_dl`) 사용.


#### 4.2.5. 프로젝트 결과
**머신러닝 모델 성능 비교**:

| Model                     | Accuracy | Precision | Recall | F1-Score | ROC-AUC |
| :------------------------ | :------- | :-------- | :----- | :------- | :------ |
| SVM (Linear Kernel)       | 0.6665   | 0.6610    | 0.6279 | 0.6440   | 0.7227  |
| Logistic Regression       | 0.6677   | 0.6649    | 0.6215 | 0.6425   | 0.7321  |
| Multinomial Naive Bayes   | 0.6650   | 0.6731    | 0.5884 | 0.6279   | 0.7314  |
| LightGBM                  | 0.6518   | 0.6500    | 0.5964 | 0.6221   | 0.7113  |
| Random Forest             | 0.6661   | 0.6913    | 0.5513 | 0.6134   | 0.7211  |
| Decision Tree             | 0.6068   | 0.5941    | 0.5730 | 0.5834   | 0.6058  |
| K-Nearest Neighbors       | 0.5444   | 0.7667    | 0.0743 | 0.1354   | 0.5395  |

* **Logistic Regression**과 **SVM (Linear Kernel)**이 F1-Score 기준 약 0.64로 가장 높은 성능을 보였습니다. Logistic Regression은 ROC-AUC 0.7321로 가장 높았습니다.
* **Multinomial Naive Bayes**도 0.6279의 F1-Score와 0.7314의 ROC-AUC로 준수한 성능을 보였습니다.
* **KNN**은 재현율이 매우 낮아 특정 클래스 예측에 어려움을 보였습니다.

**딥러닝 모델 성능**:
* 정확도 그래프:
훈련 정확도 (파란색 선): 에포크가 진행됨에 따라 꾸준히 상승하여 약 10~15 에포크 이후 0.75 이상에 도달했습니다.
검증 정확도 (주황색 선): 훈련 초반에는 훈련 정확도와 함께 상승하지만, 약 5 에포크 이후부터는 0.65 수준에서 정체되거나 미미하게 변동하는 양상을 보였습니다.
* 훈련 정확도와 검증 정확도 간의 격차가 점차 벌어지는 것이 명확하게 관찰됩니다. 이는 모델이 훈련 데이터에 과도하게 최적화되어 과적합이 발생했음을 나타냅니다.
* ![image](https://github.com/user-attachments/assets/5bda89fb-f24f-4e3f-ac60-0a8198739ddf)

**모델 종합 비교 및 결론**:
Logistic Regression과 SVM (Linear Kernel)이 F1-Score 약 0.64로 가장 높은 성능을 기록했습니다.
MLP 모델은 약 66%의 테스트 정확도를 달성했습니다. 텍스트 데이터의 복잡성과 효과적인 특징 추출의 한계가 주요 원인으로 분석됩니다.


---

### 4.3. 세 번째 데이터셋: 음성 특징 기반 성별 분류

#### 4.3.1. 데이터셋 개요 및 전처리
* **데이터셋**: `voice.csv` 파일. 3168개의 샘플과 21개의 특징((3168, 21))으로 구성.
* **특징**: `meanfreq`, `sd`, `median`, `Q25`, `Q75`, `IQR`, `skew`, `kurt`, `sp.ent`, `sfm`, `mode`, `centroid`, `meanfun`, `minfun`, `maxfun`, `meandom`, `mindom`, `maxdom`, `dfrange`, `modindx` 등 20개의 수치형 음성 특징.
* **타겟 변수**: `label` 컬럼('male'/'female'). `LabelEncoder`를 통해 0(female)과 1(male)로 변환. 클래스 불균형 없이 균등 분포(50%씩).
* **결측치**: 모든 컬럼에 결측치 없음.
* **스케일링**: 모든 특징이 수치형이므로, 전통 머신러닝 모델에는 `MinMaxScaler`, 딥러닝 모델에는 `StandardScaler`를 사용하여 스케일링.
* **데이터 분할**: 훈련(70%), 검증(15%), 테스트(15%) 세트로 분할.

#### 4.3.2. 머신러닝 모델 성능
Logistic Regression, Decision Tree, Random Forest, SVM (Linear Kernel), K-Nearest Neighbors, Gaussian Naive Bayes, LightGBM 모델을 훈련 및 평가.

**모델별 성능 요약**:

| Model                 | Accuracy | Precision | Recall | F1-Score | ROC-AUC |
| :-------------------- | :------- | :-------- | :----- | :------- | :------ |
| LightGBM              | 0.9890   | 0.9844    | 0.9937 | 0.9890   | 0.9976  |
| Random Forest         | 0.9842   | 0.9812    | 0.9874 | 0.9843   | 0.9989  |
| K-Nearest Neighbors   | 0.9795   | 0.9720    | 0.9874 | 0.9797   | 0.9990  |
| SVM (Linear Kernel)   | 0.9716   | 0.9628    | 0.9811 | 0.9719   | 0.9973  |
| Decision Tree         | 0.9716   | 0.9746    | 0.9685 | 0.9715   | 0.9716  |
| Logistic Regression   | 0.9637   | 0.9509    | 0.9779 | 0.9642   | 0.9965  |
| Gaussian Naive Bayes  | 0.9117   | 0.8991    | 0.9274 | 0.9130   | 0.9544  |

* **전반적인 고성능**: 모든 모델이 90% 이상의 높은 정확도를 보였으며, 음성 특징이 성별 분류에 매우 효과적임을 알 수 있음음.
* **최고 성능 모델**:
    * **LightGBM**: F1-Score 0.9890, ROC-AUC 0.9976으로 가장 뛰어난 성능. 특히 Recall이 0.9937로 높아 남성 음성 식별 능력이 탁월.
    * **Random Forest**: F1-Score 0.9843, ROC-AUC 0.9989로 매우 우수.
    * **K-Nearest Neighbors**: F1-Score 0.9797, ROC-AUC 0.9990으로 가장 높은 ROC-AUC 기록.
* **ROC 곡선**: 모든 모델이 0.95 이상의 높은 ROC-AUC 값을 가지며, 곡선이 좌측 상단에 가깝게 위치하여 매우 우수한 분류 성능을 보였습니다. 


#### 4.3.3. 딥러닝 MLP 모델 성능
**MLP 모델 구조**:
* 입력 계층: 20개 노드.
* 은닉 계층 1: 256개 노드, ReLU, L2 정규화 (0.001), Dropout (0.5).
* 은닉 계층 2: 128개 노드, ReLU, L2 정규화 (0.001), Dropout (0.5).
* 은닉 계층 3: 64개 노드, ReLU, L2 정규화 (0.001), Dropout (0.3).
* 출력 계층: 1개 노드, Sigmoid (이진 분류).
* 총 46,593개의 학습 가능한 파라미터.
* **학습 과정 및 콜백**: Adam 옵티마이저, binary_crossentropy 손실 함수, accuracy 평가 지표. `ModelCheckpoint`, `EarlyStopping` (val_accuracy 10 에포크), `ReduceLROnPlateau` (val_loss 5 에포크) 콜백 적용.
* **학습 과정 그래프 분석**: (MLP Loss/Accuracy 그래프) 훈련 및 검증 정확도가 빠르게 상승하여 안정화되고, 손실은 꾸준히 감소하여 과적합 없이 잘 일반화되었음을 보여주었습니다. EarlyStopping에 의해 약 22 에포크에서 학습이 조기 중단되고 최적 가중치가 복원되었습니다.
* ![image](https://github.com/user-attachments/assets/cdc8c72e-6777-48b2-a074-d2504c480952)

* **최종 MLP 모델 평가 결과**:
    * **테스트 손실: 0.1561**
    * **테스트 정확도: 0.9832**

#### 4.3.4. 모델 성능 종합 비교 및 결론
음성 특징 기반 성별 분류 문제에서, 전통적인 머신러닝 모델과 딥러닝 MLP 모델 모두 매우 우수한 성능을 달성했습니다. LightGBM (F1-Score: 0.9890)이 근소한 차이로 가장 높은 성능을 기록했으며, 딥러닝 MLP 모델도 테스트 정확도 0.9832로 거의 동등한 수준의 높은 성능을 보였습니다. 음성 특징이 성별 분류에서 매우 효과적인 데이터임을 알 수 있습니다.

---

### 4.4. 네 번째 데이터셋: 얼굴 이미지 기반 성별 분류 딥러닝 모델 성능 분석

#### 4.4.1. 데이터셋 개요 및 전처리
* **데이터셋**: UTKFace 데이터셋. 총 23,708개의 얼굴 이미지로 구성. 파일명은 `[age]_[gender]_[race]_[date].jpg` 형식으로 성별(0: 남성, 1: 여성) 정보 포함.
* **데이터 로딩 및 파싱**: 이미지 파일명을 파싱하여 나이, 성별, 인종 정보를 추출하고 DataFrame으로 구성.
* **레이블 인코딩**: 성별 레이블은 이미 0(남성) 또는 1(여성)의 수치형으로 이진 분류에 직접 활용.
* **데이터 분할**: 전체 데이터셋을 훈련 세트와 테스트 세트 검증 세트(6:2:2 비율)로 분할.
* **이미지 전처리 및 데이터 증강**: 모든 이미지는 128x128 픽셀, 3채널 RGB로 리사이징되고 픽셀 값은 0-1로 정규화. `ImageDataGenerator`를 활용하여 훈련 데이터에 대해 회전, 이동, 확대/축소, 좌우 반전, 밝기 변경 등 데이터 증강 적용.

#### 4.4.2. 딥러닝 모델 정의의



**모델 정의 (Sequential API 기반 CNN 모델)**:
초기 모델 학습 시, UTKFace 데이터셋에서는 심각한 과적합 문제가 관찰되었습니다. 훈련 정확도는 빠르게 100%에 근접했지만, 검증 정확도는 80%대 후반에서 정체되거나 감소하는 경향을 보였습니다. 또한, 훈련 손실은 지속적으로 감소했으나, 검증 손실은 빠르게 증가하는 양상을 나타냈습니다. 이러한 과적합 문제를 해결하고 모델의 일반화 성능을 향상시키기 위해 다음과 같은 전략을 적용했습니다.

데이터 증강 도입: 훈련 데이터에 RandomFlip, RandomRotation, RandomZoom을 적용하여 모델이 학습하는 데이터의      다양성을 인위적으로 늘렸습니다. 이는 모델이 실제 환경에서 접할 수 있는 다양한 변형에 더 잘 대응하도록 돕습니다.

배치 정규화 추가: 각 합성곱 레이어 뒤에 배치 정규화를 추가하여 학습 과정을 안정화하고, 더 높은 학습률을 사용할 수 있게 하여 과적합 억제에 기여했습니다.

* **구조**: `Rescaling(1./255)` → 여러 Conv2D (32, 64, 128 필터, ReLU) → MaxPooling2D 블록 반복 → Flatten() → Dense(128, activation='relu') → Dropout(0.5) → Dense(1, activation='sigmoid').
* **컴파일 설정**: `optimizer='adam'`, `loss='binary_crossentropy'`, `metrics=['accuracy']`.

#### 4.4.3. 학습 과정 분석
학습 과정 그래프 분석:
* **정확도 (Accuracy) 변화**: 훈련 정확도는 꾸준히 상승하여 0.98 이상으로 매우 높은 값을 기록했습니다. 검증 정확도는 훈련 초기에는 빠르게 상승한 후, 약 10 에포크 이후부터 0.90 ~ 0.91 사이에서 안정적으로 유지되었습니다. 이전의 심각한 과적합 상태와 비교했을 때, 훈련 정확도와 검증 정확도 간의 격차는 여전히 존재하지만, 검증 정확도 자체가 90% 이상으로 크게 향상되어 모델의 일반화 능력이 개선되었음을 시사합니다.
* **손실 (Loss) 변화**: 훈련 손실은 지속적으로 감소하여 0.1 이하의 낮은 값을 보였습니다. 반면, 검증 손실은 초기에 감소하다가 약 10 에포크 이후부터는 다시 상승하는 경향을 보였습니다. 이는 데이터 증강 및 배치 정규화를 통해 과적합이 상당 부분 완화되었음에도 불구하고, 여전히 미미한 수준의 과적합이 남아있음을 나타냅니다.
* ![image](https://github.com/user-attachments/assets/cc3e5cd7-50c1-43e5-aa01-fca55ffec36e)

* **최종  결과**:
    * 최고 검증 정확도: 0.92155 
    * 최종 테스트 손실: 0.2915
    * 최종 테스트 정확도: 0.9112

#### 4.4.4. 모델 성능 결론

*  데이터 증강과 배치 정규화를 적용함으로써 UTKFace 모델의 일반화 성능이 크게 향상되었습니다. 0.9112의 테스트 정확도는 얼굴 이미지 기반 성별 분류 task에서 매우 준수한 성능으로 판단됩니다. 비록 검증 손실에서 약간의 과적합 징후가 남아있지만, 초기 모델의 심각한 과적합 문제를 성공적으로 완화하고 유의미한 분류 성능을 달성했습니다.


---

### 5. 프로젝트 종합 결론 및 추후 발전 방향

#### 5.1. 프로젝트 종합 결론
본 프로젝트에서는 얼굴 수치형 특징 (`Gender Classification V7`), 소셜 미디어 텍스트 및 사용자 프로필 데이터 (`Twitter User Gender Classification`), 음성 특징 (`Voice`), 그리고 얼굴 이미지 (`UTKFace`)라는 네 가지 상이한 데이터셋을 활용하여 성별 분류 모델을 구축하고 그 성능을 비교 분석했습니다. 각 데이터셋의 특성에 맞는 전처리 방식과 다양한 머신러닝 및 딥러닝 모델을 적용한 결과 다음과 같은 결론을 도출할 수 있었습니다.

* **데이터셋별 성능 차이**:
    * **얼굴 수치형 특징 (Gender Classification V7)**: Random Forest (F1-Score 0.9850) 및 Logistic Regression (정확도 0.9640)이 매우 높은 정확도를 달성했습니다. 딥러닝 MLP 모델(정확도 0.981) 또한 뛰어난 성능을 보였습니다. 이는 얼굴의 특정 수치형 특징이 성별 분류에 매우 강력하고 명확한 정보를 제공하며, 데이터의 노이즈가 적고 특징 간의 관계가 비교적 단순했기 때문에 고성능 달성이 용이했음을 의미합니다.
    * **음성 특징 (Voice)**: LightGBM (F1-Score 0.9890) 및 딥러닝 MLP (정확도 0.9832)가 뛰어난 성능을 보였습니다. 음성 특징 역시 성별 분류에 매우 효과적인 정보를 담고 있으며, 특히 앙상블 모델과 딥러닝 모델이 복잡한 음성 신호 패턴을 효과적으로 학습했습니다.
    * **소셜 미디어 텍스트 및 사용자 특징 (Twitter User Gender Classification)**: Logistic Regression, SVM (Linear Kernel)이 F1-Score 약 0.64로 비교적 높은 성능을 기록했습니다. 딥러닝 MLP 모델 또한 테스트 정확도 $0.6599$를 보이며 유사한 수준의 성능을 나타냈습니다. 텍스트 데이터의 복잡성, 높은 차원, 그리고 노이즈로 인해 얼굴 수치형 특징 및 음성 특징 데이터셋에 비해 전반적인 정확도는 낮게 나타났습니다. 이는 비정형 데이터 처리의 난이도와 한계를 보여줍니다.
    * **얼굴 이미지 (UTKFace)**: CNN 모델이 데이터 증강 및 배치 정규화와 같은 과적합 완화 기법 적용 후, 학습 과정에서 높은 훈련 정확도($0.98$ 이상)와 안정적인 검증 정확도($0.90 \sim 0.91$)를 보이며 수렴했습니다. 최종 테스트 정확도 $0.9112$를 달성하여 시각적 특징이 성별 분류에 매우 효과적임을 입증했으며, CNN이 이미지 패턴을 성공적으로 학습했음을 보여주었습니다.

* **모델 유형별 강점**:
    * **앙상블 모델 (Random Forest, LightGBM)**: `Gender Classification V7` 및 `Voice` 데이터셋처럼 특징이 명확하고 고품질인 정형 데이터 분류에서 뛰어난 일반화 성능과 높은 정확도를 제공했습니다.
    * **선형 모델 (Logistic Regression, SVM)**: `Twitter User Gender Classification` 데이터셋처럼 텍스트 특징을 TF-IDF 등으로 변환하여 고차원 희소 행렬이 된 경우에도 준수한 성능을 보이며, 선형 분류기의 강점을 보여주었습니다.
    * **딥러닝 모델 (MLP, CNN)**: 모든 데이터셋에서 높은 잠재력과 성능을 보였습니다. 특히 이미지 (`UTKFace`)와 같이 복잡한 비선형 패턴을 학습하는 데 CNN이 탁월하며, 정형 데이터 (`Gender Classification V7`, `Voice`)에서도 MLP가 뛰어난 성능을 발휘할 수 있음을 입증했습니다. 적절한 정규화 기법(Dropout, L2)과 콜백(EarlyStopping, ReduceLROnPlateau)은 과적합 방지와 안정적인 학습에 크게 기여했습니다.

* **데이터 전처리 및 특징 엔지니어링의 중요성**: 각 데이터셋의 특성에 맞는 전처리(스케일링, 인코딩, 텍스트 정제, 벡터화, 특징 공학)는 모델의 성능에 결정적인 영향을 미쳤습니다. 특히 `Twitter User Gender Classification` 데이터셋에서는 텍스트 정제와 수치형 특징 공학이 매우 중요했습니다.
#### 5.2  레퍼런스 개선점
얼굴 수치형 특징, 소셜 미디어 텍스트 및 사용자 프로필, 음성 특징, 그리고 얼굴 이미지라는 네 가지 상이한 데이터를 모두 다루고, 각각에 최적화된 전처리 및 모델링 기법을 적용하여 성능을 분석했습니다. 이는 각 데이터 유형이 성별 분류에 얼마나 효과적인지, 그리고 어떤 모델이 각 유형에 가장 적합한지에 대한 종합적인 비교 분석을 가능하게 합니다. 

#### 5.3. 추후 발전 방향
본 프로젝트는 각 데이터 유형별 성별 예측에서 유의미한 결과를 얻었지만, 다음과 같은 방향으로 추가적인 발전을 모색할 수 있습니다.

1.  **하이퍼파라미터 튜닝의 심화**: 모든 모델에 대해 `GridSearchCV`, `RandomizedSearchCV`, `Optuna`, `Keras Tuner` 등 자동화된 튜닝 도구를 활용하여 최적의 하이퍼파라미터 조합을 체계적으로 탐색하고 성능을 극대화합니다.

2.  **실시간 예측 시스템 구축 및 배포**:
    * 각 데이터셋에서 학습된 최적 모델(예: `Gender Classification V7`의 Random Forest, `Voice`의 LightGBM, `UTKFace`의 CNN)을 API 형태로 구축하고, 웹 서비스나 모바일 애플리케이션에 배포하여 실제 환경에서 사용자 데이터를 입력받아 실시간으로 성별을 예측하는 시스템을 구축하고 서비스화하는 방안을 모색합니다.

3.  **Twitter User Gender Classification 모델 성능 향상을 위한 발전 방향**:
   * 대규모 코퍼스로 미리 학습된 단어 임베딩을 활용하여 단어의 의미론적 정보를 풍부하게 벡터화합니다
   * 문맥 기반 임베딩 및 트랜스포머 모델: BERT, GPT, RoBERTa 등과 같은 최신 트랜스포머 기반의 사전 학습된 언어 모델을 활용합니다
   * RNN 계열 모델 LSTM이나 GRU와 같은 순환 신경망 계층을 딥러닝 모델에 추가합니다. 이 모델들은 텍스트 시퀀스의 시간적/순차적 의존성을 학습하는 데 효과적이며, 장기 의존성 문제에 강점을 가집니다.
   * 드롭아웃 비율 및 위치 조정, L1/L2 규제 강화,배치 정규화 추가 ,조기 종료  재조정 등을 통한 과적합 완화 전략 강화

